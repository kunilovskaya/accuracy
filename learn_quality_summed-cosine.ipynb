{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script is an attempt to classify good and bad translations from RusLTC\n",
    "\n",
    "Representation and learning method proposed:\n",
    "\n",
    "use trained bi-lingual word embeddings (/home/masha/MUSE/rig1_res/vector-en.vec and vector-ru.vec) to capture accuracy of translations against their sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io ### https://docs.python.org/3/library/io.html\n",
    "import sys,os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "# # TensorFlow and tf.keras\n",
    "# import logging\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from keras.callbacks import TensorBoard, EarlyStopping\n",
    "# from keras import backend, preprocessing\n",
    "# from keras.layers import Dense, Input, LSTM, Bidirectional\n",
    "# from keras.models import Model\n",
    "# from keras.models import load_model as load_keras_model\n",
    "# from keras.layers import Embedding\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# import pydot\n",
    "# from keras.utils import to_categorical\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "# ## to avoid reloading kernel after changes to imported modules\n",
    "# # import importlib\n",
    "# # import HTQ_functions as mm\n",
    "# # importlib.reload(mm)\n",
    "\n",
    "# # import functions as mm1\n",
    "# # importlib.reload(mm1)\n",
    "\n",
    "# ## import the functions from the helper scripts\n",
    "# # from acc_functions import \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    \n",
    "    # both open methods return class '_io.TextIOWrapper'\n",
    "    \n",
    "    if emb_path.endswith('.gz'): \n",
    "        f = gzip.open(emb_path, 'rt', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "        \n",
    "    elif emb_path.endswith('.vec') or emb_path.endswith('.txt'):\n",
    "        f = io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "        \n",
    "    for i, line in enumerate(f):\n",
    "        ## to skip the first line (header) one can use next(f) or the condition below\n",
    "        if i == 0:\n",
    "            split = line.split()\n",
    "            assert len(split) == 2\n",
    "        else:\n",
    "            word, vect = line.rstrip().split(' ', 1) # stops the splitting after the first occurence\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, word #'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors) # stack the sequence of input arrays vertically to make a single array\n",
    "    # the list of vectors is aligned by dimentions in an array\n",
    "    return embeddings, id2word, word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata(directory):\n",
    "    ourdic = []\n",
    "    print('Collecting data from the files...')\n",
    "    for subdir in os.listdir(directory):\n",
    "        files = [f for f in os.listdir(os.path.join(directory, subdir)) if f.endswith('.conllu')]\n",
    "        for f in files:\n",
    "            rowdic = {'doc': f.strip(), 'group': subdir}\n",
    "            doc = open(os.path.join(directory, subdir, f))\n",
    "            text = doc.read().strip() #.replace('\\n', ' ')\n",
    "            doc.close()\n",
    "            rowdic['text'] = text\n",
    "            ourdic.append(rowdic)\n",
    "    ourdic = pd.DataFrame(ourdic)\n",
    "    return ourdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(data, labels, classes):\n",
    "    # Here goes the 2-D plotting of the data...\n",
    "    pca = PCA(n_components=2)\n",
    "    x_r = pca.fit_transform(data)\n",
    "    plt.figure()\n",
    "    # consistent colors\n",
    "    cols = ['red', 'green', 'orange', 'blue', 'grey']\n",
    "    colors = {}\n",
    "    for i,name in enumerate(classes):\n",
    "        colors[name] = cols[i]\n",
    "#     colors = {'bad': 'red', 'good': 'green'}\n",
    "    lw = 2\n",
    "\n",
    "    for target_name in classes:\n",
    "        plt.scatter(x_r[labels == target_name, 0], x_r[labels == target_name, 1], s=1, color=colors[target_name],\n",
    "                    label=target_name, alpha=.8, lw=lw)\n",
    "    plt.legend(loc='best', scatterpoints=1, prop={'size': 15})\n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "    #plt.savefig('plot.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return x_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_value(key, dic=None):\n",
    "    # Get the values for keys\n",
    "    if key in dic:\n",
    "        return dic[key]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from the files...\n",
      "                  doc group                                               text\n",
      "0  RU_1_244_35.conllu   bad  весь_DET правда_NOUN о_ADP гмый_PROPN сторонни...\n",
      "1   RU_1_271_4.conllu   bad  не_PART посещать_VERB 'д_NOUN странный_ADJ реб...\n",
      "2   RU_1_150_2.conllu   bad  последний_ADJ книга_NOUN роджер::пенроуз_PROPN...\n",
      "3   RU_1_244_1.conllu   bad  весь_DET правда_NOUN о_ADP генетически_ADV мод...\n",
      "4  RU_1_274_41.conllu   bad  газета_PROPN нью-йорк::таймз_PROPN xx_NUM октя...\n",
      "{'good', 'source', 'bad'}\n"
     ]
    }
   ],
   "source": [
    "## preprosessing from https://github.com/akutuzov/webvectors/blob/master/preprocessing/rus_preprocessing_udpipe.py\n",
    "datadir = '/home/masha/accuracy/data/lempos/'  # The path to where subdirectories whith text files are\n",
    "\n",
    "df = preparedata(datadir)\n",
    "print(df.head())\n",
    "labels = df['group']\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000 240000\n",
      "240000 240000\n",
      "[('Paul::Evans_PROPN', 152516), ('flu_NOUN', 13856), ('banc_NOUN', 59570), ('hilariously_ADV', 78145), ('common_ADJ', 348)]\n",
      "[('промстройбанк_PROPN', 209428), ('гант_PROPN', 118875), ('osterreichische_PROPN', 90067), ('власьевский_ADJ', 119995), ('розвадовский_PROPN', 232237)]\n",
      "(240000, 300)\n"
     ]
    }
   ],
   "source": [
    "src_path = '/home/masha/MUSE/rig1_res/vectors-en.vec'\n",
    "tgt_path = '/home/masha/MUSE/rig1_res/vectors-ru.vec'\n",
    "\n",
    "nmax = 240000  # maximum number of word embeddings to load\n",
    "\n",
    "src_embeddings, src_id2word, src_word2id = load_vec(src_path, nmax)\n",
    "print(len(src_embeddings), len(src_id2word))\n",
    "\n",
    "tgt_embeddings, tgt_id2word, tgt_word2id = load_vec(tgt_path, nmax)\n",
    "print(len(tgt_embeddings), len(tgt_id2word))\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "print(list(islice(src_word2id.items(),5)))\n",
    "print(list(islice(tgt_word2id.items(),5)))\n",
    "\n",
    "## the size is controlled by a thres at uploading time\n",
    "print(tgt_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 0.02954  0.11362 -0.0327  ... -0.07555 -0.06493 -0.01583]\n",
      " [-0.02412  0.00086  0.04388 ...  0.01334  0.04463 -0.01691]\n",
      " [ 0.01785  0.0805  -0.01598 ... -0.03036 -0.03552 -0.01519]\n",
      " [ 0.10832  0.05242 -0.04355 ... -0.10485 -0.03382 -0.03843]\n",
      " [ 0.01436 -0.04104  0.09711 ... -0.03474  0.02216  0.10514]]\n"
     ]
    }
   ],
   "source": [
    "print(type(tgt_embeddings))\n",
    "print(tgt_embeddings[:5])\n",
    "# print(tgt_embeddings[15115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lose sources:\n",
      " (542, 3)\n",
      "Separate df for sources:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>EN_1_101.conllu</td>\n",
       "      <td>source</td>\n",
       "      <td>pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>EN_1_102.conllu</td>\n",
       "      <td>source</td>\n",
       "      <td>anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>EN_1_114.conllu</td>\n",
       "      <td>source</td>\n",
       "      <td>product_NOUN placement_NOUN on_ADV broadway_VE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 doc   group  \\\n",
       "608  EN_1_101.conllu  source   \n",
       "580  EN_1_102.conllu  source   \n",
       "576  EN_1_114.conllu  source   \n",
       "\n",
       "                                                  text  \n",
       "608  pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...  \n",
       "580  anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...  \n",
       "576  product_NOUN placement_NOUN on_ADV broadway_VE...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transform the df to align each target with its source: doc, src, tgt, label\n",
    "targets_df = df[~(df['group']=='source')]\n",
    "print('Lose sources:\\n',targets_df.shape)\n",
    "sources_df = df[df['group']=='source']\n",
    "sources_df = sources_df.sort_values('doc')\n",
    "print('Separate df for sources:')\n",
    "sources_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned text pairs:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>group</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>RU_1_101_9.conllu</td>\n",
       "      <td>good</td>\n",
       "      <td>pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...</td>\n",
       "      <td>pussy_PROPN riot_PROPN путин_PROPN против_ADP ...</td>\n",
       "      <td>EN_1_101.conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RU_1_101_3.conllu</td>\n",
       "      <td>bad</td>\n",
       "      <td>pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...</td>\n",
       "      <td>пусси::райот_PROPN путин_PROPN против_ADP панк...</td>\n",
       "      <td>EN_1_101.conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RU_1_101_8.conllu</td>\n",
       "      <td>bad</td>\n",
       "      <td>pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...</td>\n",
       "      <td>пусси::райот_PROPN судебный_ADJ разбирательств...</td>\n",
       "      <td>EN_1_101.conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>RU_1_102_6.conllu</td>\n",
       "      <td>good</td>\n",
       "      <td>anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...</td>\n",
       "      <td>служба_NOUN по_ADP борьба_NOUN с_ADP наркотик_...</td>\n",
       "      <td>EN_1_102.conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>RU_1_102_15.conllu</td>\n",
       "      <td>bad</td>\n",
       "      <td>anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...</td>\n",
       "      <td>управление_PROPN по_ADP борьба_NOUN с_ADP нарк...</td>\n",
       "      <td>EN_1_102.conllu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    doc group  \\\n",
       "254   RU_1_101_9.conllu  good   \n",
       "62    RU_1_101_3.conllu   bad   \n",
       "11    RU_1_101_8.conllu   bad   \n",
       "471   RU_1_102_6.conllu  good   \n",
       "119  RU_1_102_15.conllu   bad   \n",
       "\n",
       "                                                source  \\\n",
       "254  pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...   \n",
       "62   pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...   \n",
       "11   pussy_PROPN riot_PROPN putin_ADJ v_NOUN punk_N...   \n",
       "471  anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...   \n",
       "119  anti_PROPN drug_PROPN agency_PROPN seeks_PROPN...   \n",
       "\n",
       "                                                target             temp  \n",
       "254  pussy_PROPN riot_PROPN путин_PROPN против_ADP ...  EN_1_101.conllu  \n",
       "62   пусси::райот_PROPN путин_PROPN против_ADP панк...  EN_1_101.conllu  \n",
       "11   пусси::райот_PROPN судебный_ADJ разбирательств...  EN_1_101.conllu  \n",
       "471  служба_NOUN по_ADP борьба_NOUN с_ADP наркотик_...  EN_1_102.conllu  \n",
       "119  управление_PROPN по_ADP борьба_NOUN с_ADP нарк...  EN_1_102.conllu  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned = targets_df.copy()\n",
    "aligned.insert(loc=2, column='source', value=None)\n",
    "aligned.columns = ['doc', 'group', 'source', 'target']\n",
    "print('Aligned text pairs:\\n')\n",
    "# print(aligned.head())\n",
    "aligned['temp'] = aligned['doc'].replace(to_replace='RU',value=r'EN', regex=True)\n",
    "aligned['temp'] = aligned['temp'].replace(to_replace='_\\d+\\.conllu',value=r'.conllu', regex=True)\n",
    "aligned = aligned.sort_values('temp')\n",
    "# print(aligned.head())\n",
    "sfns = aligned['temp'].tolist()\n",
    "for i in sfns:\n",
    "    aligned.loc[aligned.temp == i, 'source'] = sources_df.loc[sources_df['doc'] == i, 'text'].item()\n",
    "aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Distribution of classes in the dataset:\n",
      "       doc  source  target  temp\n",
      "group                           \n",
      "bad    213     213     213   213\n",
      "good   329     329     329   329\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "ru_xtrain0 = aligned['target']\n",
    "en_xtrain0 = aligned['source']\n",
    "\n",
    "y_train = aligned['group'].tolist()\n",
    "classes = sorted(list(set(aligned['group'].tolist())))\n",
    "print('===========================')\n",
    "print('Distribution of classes in the dataset:')\n",
    "print(aligned.groupby('group').count())\n",
    "print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random target doc: ['ученый_PROPN', 'против_ADP', 'нобелевский_ADJ', 'премия_NOUN', 'нобелевский_ADJ', 'премия_NOUN', 'по_ADP', 'психология_NOUN', 'медицина_NOUN', 'физик_NOUN', 'или_CCONJ', 'химия_NOUN', 'это_PRON', 'самый_ADJ', 'авторитетный_ADJ', 'и_CCONJ', 'почетный_ADJ', 'награда_NOUN', 'в_ADP', 'область_NOUN']\n",
      "\n",
      "First target doc: ['весь_DET', 'правда_NOUN', 'о_ADP', 'гмый_PROPN', 'сторонник_NOUN', 'генномодифицировать_ADJ', 'зерно_NOUN', 'настаивать_VERB', 'что_SCONJ', 'это_PRON', 'единственный_ADJ', 'способ_NOUN', 'справляться_VERB', 'с_ADP', 'то_PRON', 'что_SCONJ', 'прокармливать_VERB', 'густонаселенный_ADJ', 'мир_NOUN', 'критика_NOUN']\n"
     ]
    }
   ],
   "source": [
    "## Have a look at a random document \n",
    "doc = random.choice(range(20))\n",
    "# print(type(ru_xtrain0[doc]))\n",
    "print('Random target doc:', ru_xtrain0[doc].split()[:20])\n",
    "## or at the first text to avoid an extra variable\n",
    "print('\\nFirst target doc:', ru_xtrain0[0].split()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text represented with word vectors indices: [0, 0, 0, 0, 3814, 0, 87]\n",
      "Target text represented with word vectors indices: [38362, 26358, 5961, 0, 18779, 1532, 364]\n",
      "<class 'list'>\n",
      "number of words=itm: 706 570\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "dims of each word embedding (300,)\n",
      "300\n",
      "Same text as a list of embeddings (stored as arrays): <class 'numpy.ndarray'>\n",
      "I expect 300 here! 300 300\n",
      "========\n",
      "[-14.47449  -2.46295  22.62501  -7.47731  27.04624] [  4.3076   21.94698   1.03974 -11.85549   7.48334]\n",
      "600\n",
      "[-14.47449  -2.46295  22.62501  -7.47731  27.04624] [  4.3076   21.94698   1.03974 -11.85549   7.48334]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is the list of summed and concatenated embeddings for each text pair\n"
     ]
    }
   ],
   "source": [
    "### manual inspection\n",
    "ru_indexed = [[get_dic_value(w,tgt_word2id) for w in text.split()] for text in ru_xtrain0]\n",
    "en_indexed = [[get_dic_value(w,src_word2id) for w in text.split()] for text in en_xtrain0]\n",
    "print('Source text represented with word vectors indices:', en_indexed[0][:7])\n",
    "print('Target text represented with word vectors indices:', ru_indexed[0][:7])\n",
    "## find summed text vectors: for that stack a list of vectors of size = text length\n",
    "ru_embedded = [[tgt_embeddings[idx] for idx in itm] for itm in ru_indexed]\n",
    "en_embedded = [[src_embeddings[idx] for idx in itm] for itm in en_indexed]\n",
    "print(type(ru_embedded[0]))\n",
    "print('number of words=itm:',len(en_embedded[0]),len(ru_embedded[0]))\n",
    "print(type(en_embedded[0][0][:5]))\n",
    "print(type(ru_embedded[0][0][:5]))\n",
    "print('dims of each word embedding', ru_embedded[0][0].shape)\n",
    "print(len(ru_embedded[0][0]))\n",
    "print('Same text as a list of embeddings (stored as arrays):', type(ru_embedded[doc][:20][0]))\n",
    "\n",
    "## 542 itms, each is a list of arrays to be summed up\n",
    "en_av_texts_emb0 = np.sum(en_embedded[0], axis=0)\n",
    "ru_av_texts_emb0 = np.sum(ru_embedded[0], axis=0)\n",
    "\n",
    "print('I expect 300 here!',len(en_av_texts_emb0),len(ru_av_texts_emb0))\n",
    "print('========')\n",
    "print(en_av_texts_emb0[:5],ru_av_texts_emb0[:5])\n",
    "\n",
    "## and concatenate to be added to the df\n",
    "# paired = list(zip(list(en_av_texts_emb0), list(ru_av_texts_emb0)))\n",
    "# print(paired[:3])\n",
    "\n",
    "X = np.array(np.concatenate((en_av_texts_emb0, ru_av_texts_emb0), axis=None))\n",
    "print('This is the list of summed and concatenated embeddings for each text pair', file=sys.stderr)\n",
    "print(len(X))\n",
    "print(X[:5], X[300:305])\n",
    "\n",
    "# print('Same text as a summed embedding of size 300:', ru_av_texts_emb0[doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here on I am constructing a discriminative classifier that is going to use (pca-transformed to size 100)  summed and joint 200 embedding components as features for 542 texts\n",
    "\n",
    "This does not make theoretical sense, because there are more features than observations (therefore pca-transform and gridsearch are added)\n",
    "\n",
    "To address the problem of our model/task being underdetermined (the number of features is greater than the number of data points) we use regularization: hyperparameter tuning via grid search (see https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/ch04.html)\n",
    "\n",
    "====Future=====\n",
    "\n",
    "What I need (as a real model that would heed word order and syntactic properties and not only BOW semantics as in the above scenario) is a neural model with an LSTM layer that is going to look at every word in ST+TT represented by corresponding bilingual embeddings of size 300\n",
    "\n",
    "Number of features is for the LSTM input is 300 as it looks at texts as a sequence of embeddings, processig one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## represent texts with embeddings, get summed up vectors, maybe reduce their dimensionality \n",
    "def get_summed_emb(embs, w2idx, texts, reduce=0):\n",
    "    indexed0 = [[get_dic_value(w,w2idx) for w in text.split()] for text in texts]\n",
    "    ## ignore OOV words by deleting id=0\n",
    "    indexed = [[idx for idx in text if idx != 0] for text in indexed0]\n",
    "    print('OOV lost:', indexed[0][:7])\n",
    "    embedded = [[embs[idx] for idx in itm] for itm in indexed]\n",
    "    out = [np.sum(itm, 0) for itm in embedded]\n",
    "    if reduce:\n",
    "        pca = PCA(n_components=100)\n",
    "        out = pca.fit_transform(out)\n",
    "    else:\n",
    "        out = out\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV lost: [3814, 87, 948, 163, 5402, 9, 807]\n",
      "<class 'list'>\n",
      "542\n",
      "300\n",
      "OOV lost: [38362, 26358, 5961, 18779, 1532, 364, 42515]\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "en_av_texts_emb = get_summed_emb(src_embeddings, src_word2id, en_xtrain0)\n",
    "print(type(en_av_texts_emb))\n",
    "print(len(en_av_texts_emb))\n",
    "print(len(en_av_texts_emb[0]))\n",
    "ru_av_texts_emb = get_summed_emb(tgt_embeddings, tgt_word2id, ru_xtrain0)\n",
    "print(len(ru_av_texts_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n",
      "542\n",
      "[ -2.26905  -0.66583   6.94597 -10.57235   3.26352] [-2.10258 -2.70856  8.13564 -9.80701 -0.97098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is the list of summed and concatenated embeddings for each text pair\n"
     ]
    }
   ],
   "source": [
    "## and concatenate to be added to the df\n",
    "paired = list(zip(list(en_av_texts_emb), list(ru_av_texts_emb)))\n",
    "print(len(paired))\n",
    "\n",
    "XX = np.array([np.concatenate((p[0],p[1]), axis=None) for p in paired])\n",
    "print('This is the list of summed and concatenated embeddings for each text pair', file=sys.stderr)\n",
    "print(len(XX))\n",
    "print(XX[0][:5], XX[0][300:305])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n",
      "{'good', 'bad'}\n",
      "(542, 600)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(set(y_train))\n",
    "print(XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets classify!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def my_SVM(x,y, algo='SVM', grid=False):\n",
    "    ## StandardScaler scales each column (feature) to have 0 mean and unit variance.\n",
    "    sc = StandardScaler() ## same as z-transformation; is your data normally distributed to use this?\n",
    "    x = sc.fit_transform(x)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    if algo == 'SVM':\n",
    "        clf = SVC(decision_function_shape='ovo', kernel='rbf', gamma='auto',\n",
    "                  random_state=100, verbose=False, probability=True, class_weight=\"balanced\")\n",
    "        if grid:\n",
    "            refit_score='f1_score'\n",
    "            scoring='f1_macro'\n",
    "            tuned_parameters = {'kernel': ['rbf','linear'], 'gamma': [0.1, 1, 10, 100],'C': [1, 10, 100, 1000]}\n",
    "            grid_search = GridSearchCV(clf, tuned_parameters, refit=refit_score, cv=skf, scoring=scoring)\n",
    "            grid_search.fit(x, y)\n",
    "\n",
    "            clf.set_params(**grid_search.best_params_)\n",
    "            best_dict = grid_search.best_params_\n",
    "            print('Best param:\\n', best_dict)\n",
    "        print('we are classifying with:\\n', clf)\n",
    "        \n",
    "    elif algo == 'dummy':\n",
    "        strategy='stratified'\n",
    "        print('\\n====DummyBaseline (%s)====' % strategy)\n",
    "        clf = DummyClassifier(strategy=strategy,random_state=42) # 'stratified','uniform', 'most_frequent'\n",
    "\n",
    "    ## this function is simpler than cross_validate, it returns a list of scores on just one specified metric, rather than a dict and tons of other info in that dict\n",
    "    scores_f = cross_val_score(clf, x, y, cv=skf, scoring='f1_macro')  # cv = loo f1_macro\n",
    "    scores_acc = cross_val_score(clf, x, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "    print(\"F1 over 10folds: \", scores_f.mean())\n",
    "    print(\"Accuracy over 10folds: \", scores_acc.mean())\n",
    "    \n",
    "    preds = cross_val_predict(clf, x, y, cv=skf)\n",
    "    print('Cross-validated estimates for data points')\n",
    "    print(classification_report(y, preds))\n",
    "    \n",
    "    print('===ConfusionMatrix===')\n",
    "    cnf_matrix = confusion_matrix(y, preds)\n",
    "    print(cnf_matrix)\n",
    "    \n",
    "    \n",
    "    # get measures on the minority class\n",
    "    print('\\n====MinorityClass====')\n",
    "    my_dict = classification_report(y, preds, output_dict=True)\n",
    "    minorf1 = my_dict['bad']['f1-score']\n",
    "    print('F1 on the minority class:', np.average(minorf1).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542, 600)\n",
      "we are classifying with:\n",
      " SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=100, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "F1 over 10folds:  0.6068528732661612\n",
      "Accuracy over 10folds:  0.6088609364081062\n",
      "Cross-validated estimates for data points\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.77      0.61       213\n",
      "        good       0.77      0.51      0.61       329\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       542\n",
      "   macro avg       0.64      0.64      0.61       542\n",
      "weighted avg       0.66      0.61      0.61       542\n",
      "\n",
      "===ConfusionMatrix===\n",
      "[[163  50]\n",
      " [162 167]]\n",
      "\n",
      "====MinorityClass====\n",
      "F1 on the minority class: 0.606\n",
      "\n",
      "====DummyBaseline (stratified)====\n",
      "F1 over 10folds:  0.4782165369017871\n",
      "Accuracy over 10folds:  0.5145086080935137\n",
      "Cross-validated estimates for data points\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.37      0.32      0.34       213\n",
      "        good       0.59      0.64      0.62       329\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       542\n",
      "   macro avg       0.48      0.48      0.48       542\n",
      "weighted avg       0.50      0.51      0.51       542\n",
      "\n",
      "===ConfusionMatrix===\n",
      "[[ 68 145]\n",
      " [118 211]]\n",
      "\n",
      "====MinorityClass====\n",
      "F1 on the minority class: 0.341\n"
     ]
    }
   ],
   "source": [
    "print(XX.shape)\n",
    "my_SVM(XX, y_train, algo='SVM', grid=False)\n",
    "my_SVM(XX, y_train, algo='dummy', grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try cosine similarity between ST and TT as a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## smaller cosine = bigger angle/distance\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n",
      "[0.9579350638592249, 0.9524320243437777]\n",
      "(542, 1)\n"
     ]
    }
   ],
   "source": [
    "sims = [cosine_similarity(p[0],p[1]) for p in paired]\n",
    "print(len(sims))\n",
    "print(sims[:2])\n",
    "Xsims = np.array([sims]).transpose()\n",
    "print(Xsims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param:\n",
      " {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "we are classifying with:\n",
      " SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovo', degree=3, gamma=0.1, kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=100, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "F1 over 10folds:  0.5106311003943864\n",
      "Accuracy over 10folds:  0.5128962581792769\n",
      "Cross-validated estimates for data points\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.72      0.54       213\n",
      "        good       0.68      0.38      0.48       329\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       542\n",
      "   macro avg       0.55      0.55      0.51       542\n",
      "weighted avg       0.58      0.51      0.51       542\n",
      "\n",
      "===ConfusionMatrix===\n",
      "[[154  59]\n",
      " [205 124]]\n",
      "\n",
      "====MinorityClass====\n",
      "F1 on the minority class: 0.538\n",
      "\n",
      "====DummyBaseline (most_frequent)====\n",
      "F1 over 10folds:  0.37773326572008115\n",
      "Accuracy over 10folds:  0.6070440251572327\n",
      "Cross-validated estimates for data points\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00       213\n",
      "        good       0.61      1.00      0.76       329\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       542\n",
      "   macro avg       0.30      0.50      0.38       542\n",
      "weighted avg       0.37      0.61      0.46       542\n",
      "\n",
      "===ConfusionMatrix===\n",
      "[[  0 213]\n",
      " [  0 329]]\n",
      "\n",
      "====MinorityClass====\n",
      "F1 on the minority class: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "my_SVM(Xsims, y_train, grid=True)\n",
    "my_SVM(Xsims, y_train, algo='dummy', grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another baseline is QuEst features from https://www.quest.dcs.shef.ac.uk/\n",
    "\n",
    "I need to update RusLTC to have all quality-labeled data in the bitext format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see a separate script for:\n",
    "\n",
    "a neural model with an LSTM layer that is going to look at every word in ST+TT represented by corresponding bilingual embeddings of size 300\n",
    "\n",
    "Number of features is for the LSTM input is 300 as it looks at texts as a sequence of embeddings, processig one at a time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_CPUkerasTF",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
