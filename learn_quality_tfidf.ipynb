{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script is an attempt to classify good and bad translations from RusLTC\n",
    "\n",
    "what to use to features?\n",
    "\n",
    "Baselines\n",
    "\n",
    "(1) reproduce the results on translationese features for the enlarged dataset: good-bad F1 =0.6419, dummy baseline 0.4863 (see paper_code_HiT-IT.ipynb)\n",
    "\n",
    "If you really think about it the three types of representation below are not going to generalize well on a relatively small number of observations; these models are bound to overfit\n",
    "\n",
    "(2) try bow: token 3grams and character 5grams\n",
    "\n",
    "(3) with feature tf-idf scaling \n",
    "\n",
    "Representation and learning method proposed:\n",
    "\n",
    "(4) use trained bi-lingual word embeddings (/home/masha/MUSE/rig1_res/vector-en.vec and vector-ru.vec) to capture accuracy of translations against their sources, see a separate script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from numpy import median\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn import svm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as sc\n",
    "\n",
    "## to avoid reloading kernel after changes to imported modules\n",
    "# import importlib\n",
    "# import HTQ_functions as mm\n",
    "# importlib.reload(mm)\n",
    "\n",
    "# import functions as mm1\n",
    "# importlib.reload(mm1)\n",
    "\n",
    "## import the functions from the helper scripts\n",
    "# from acc_functions import \n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata(directory):\n",
    "    ourdic = []\n",
    "    print('Collecting data from the files...')\n",
    "    for subdir in os.listdir(directory):\n",
    "        files = [f for f in os.listdir(os.path.join(directory, subdir)) if f.endswith('.txt')]\n",
    "        for f in files:\n",
    "            rowdic = {'doc': f.strip(), 'group': subdir}\n",
    "            doc = open(os.path.join(directory, subdir, f))\n",
    "            text = doc.read().strip() #.replace('\\n', ' ')\n",
    "            doc.close()\n",
    "            rowdic['text'] = text\n",
    "            ourdic.append(rowdic)\n",
    "    ourdic = pd.DataFrame(ourdic)\n",
    "    return ourdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureselection(x, labels, n_features):\n",
    "    # Feature selection\n",
    "    ff = SelectKBest(k=n_features).fit(x, labels)\n",
    "    newdata = SelectKBest(k=n_features).fit_transform(x, labels)\n",
    "    top_ranked_features = sorted(enumerate(ff.scores_), key=lambda y: y[1], reverse=True)[:n_features]\n",
    "    top_ranked_features_indices = [x[0] for x in top_ranked_features]\n",
    "    return newdata, top_ranked_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(data, labels, classes):\n",
    "    # Here goes the 2-D plotting of the data...\n",
    "    pca = PCA(n_components=2)\n",
    "    x_r = pca.fit_transform(data)\n",
    "    plt.figure()\n",
    "    # consistent colors\n",
    "    cols = ['red', 'green', 'orange', 'blue', 'grey']\n",
    "    colors = {}\n",
    "    for i,name in enumerate(classes):\n",
    "        colors[name] = cols[i]\n",
    "#     colors = {'bad': 'red', 'good': 'green'}\n",
    "    lw = 2\n",
    "\n",
    "    for target_name in classes:\n",
    "        plt.scatter(x_r[labels == target_name, 0], x_r[labels == target_name, 1], s=1, color=colors[target_name],\n",
    "                    label=target_name, alpha=.8, lw=lw)\n",
    "    plt.legend(loc='best', scatterpoints=1, prop={'size': 15})\n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "    #plt.savefig('plot.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return x_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from the files...\n",
      "{'bad', 'good', 'source'}\n"
     ]
    }
   ],
   "source": [
    "datadir = '/home/masha/accuracy/data/raw/'  # The path to where subdirectories whith text files are\n",
    "\n",
    "data_dic = preparedata(datadir)\n",
    "### this this raw input texts and labels\n",
    "Xraw3 = data_dic['text']\n",
    "# print(Xraw[0])\n",
    "Y3 = data_dic['group']\n",
    "print(set(Y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 3)\n",
      "(542, 3)\n",
      "{'bad', 'good'}\n"
     ]
    }
   ],
   "source": [
    "## lose sources for tf-idf baseline\n",
    "print(data_dic.shape)\n",
    "data_dic = data_dic[data_dic['group'] != 'source']\n",
    "print(data_dic.shape)\n",
    "Xraw = data_dic['text']\n",
    "# print(Xraw[0])\n",
    "Y = data_dic['group']\n",
    "print(set(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the SVM-model, find best hyper-parameters for both the feature extraction and the classifier\n",
    "def gridsearch_SVM(x, y, refit_score='f1_score', algo='dummy', grid=False):\n",
    "    ## norm='l2', use_idf=True, analyzer='word', sublinear_tf=True\n",
    "    ## \n",
    "    tfidf = TfidfVectorizer(analyzer='word',ngram_range=(3, 3), lowercase=True, stop_words=None, smooth_idf=True)\n",
    "    clf = svm.SVC(decision_function_shape='ovo', kernel='rbf',\n",
    "              random_state=100, verbose=False, probability=True, class_weight=\"balanced\")\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('SVM', clf),\n",
    "    ])\n",
    "    ## 'tfidf__analyzer': ('word','char'), 'SVM__kernel': ['rbf','linear']\n",
    "    parameters = {'tfidf__max_features': (500, 1000, 5000), 'tfidf__use_idf': (True, False),'tfidf__norm': ('l1', 'l2'),\n",
    "                  'SVM__gamma': [0.01, 0.1, 1, 10],'SVM__C': [1, 10, 100]}\n",
    "    \n",
    "    if algo == 'SVM':\n",
    "        grid = GridSearchCV(pipeline, parameters, refit=refit_score, cv=skf, scoring='f1_macro',\n",
    "                                   n_jobs=4, verbose=1)\n",
    "\n",
    "        print(\"Performing grid search...\")\n",
    "        print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "        print(\"parameters:\")\n",
    "        print(parameters)\n",
    "        t0 = time()\n",
    "        grid.fit(x, y)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print()\n",
    "\n",
    "        print(\"Best score: %0.3f\" % grid.best_score_)\n",
    "        print(\"Best parameters set:\")\n",
    "        best_parameters = grid.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "        grid.refit\n",
    "\n",
    "        predicted = grid.predict(x)\n",
    "        print(\"accuracy=\", np.mean(predicted == y))\n",
    "        print(\"macro f-score\", f1_score(y, predicted, average='macro'))\n",
    "        print(\"Confusion matrix\\n\", confusion_matrix(y, predicted))\n",
    "\n",
    "        print('=====')\n",
    "        print('Unpack the pipeline and look at some distinctive features and produce cross-validated metrics for the classifier on the weighted vectors')\n",
    "\n",
    "        vectorizer = grid.best_estimator_.named_steps[\"tfidf\"]\n",
    "        ## Call the fit() function in order to tokenize and learn a vocabulary from one or more documents, \n",
    "        ## and learn the vocabulary and inverse document frequency weightings\n",
    "        # transform the raw training texts into andataset:\n",
    "        vectorizer.fit(x)\n",
    "        # summarize\n",
    "    #     print(vectorizer.vocabulary_)\n",
    "    #     print(vectorizer.idf_)\n",
    "        # encode documents\n",
    "        X_train = vectorizer.transform(x)\n",
    "    \n",
    "        # find maximum value for each of the features over dataset:\n",
    "        max_value = X_train.max(axis=0).toarray().ravel()\n",
    "        sorted_by_tfidf = max_value.argsort()\n",
    "        # get feature names\n",
    "        feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "        ## either very commonly used across documents, or are only used sparingly, and only in very long documents\n",
    "        print(\"features with lowest tfidf\")\n",
    "        print(feature_names[sorted_by_tfidf[:20]])\n",
    "\n",
    "        ## tend to appear very often in some particular documents\n",
    "        print(\"features with highest tfidf\")\n",
    "        print(feature_names[sorted_by_tfidf[-20:]])\n",
    "\n",
    "        ## PCA and SVC does not support sparse input. If used earlier in the script, it throws up 'matrix' object has no attribute 'toarray'\n",
    "        X_train = X_train.todense()\n",
    "        print(type(X_train))\n",
    "\n",
    "        classifier = grid.best_estimator_.named_steps[\"SVM\"]\n",
    "\n",
    "        print('=====')\n",
    "        print('Here goes cross-validation. Please wait a bit...')\n",
    "\n",
    "        scoring = ['precision_macro', 'recall_macro', 'f1_macro']\n",
    "        cv_scores = cross_validate(classifier, X_train, y, cv=skf, scoring=scoring, n_jobs=2)\n",
    "\n",
    "\n",
    "        print(\"Average Precision on 10-fold cross-validation: %0.3f (+/- %0.3f)\" % (\n",
    "            cv_scores['test_precision_macro'].mean(), cv_scores['test_precision_macro'].std() * 2))\n",
    "        print(\"Average Recall on 10-fold cross-validation: %0.3f (+/- %0.3f)\" % (\n",
    "            cv_scores['test_recall_macro'].mean(), cv_scores['test_recall_macro'].std() * 2))\n",
    "        print(\"Average F1 on 10-fold cross-validation: %0.3f (+/- %0.3f)\" % (\n",
    "            cv_scores['test_f1_macro'].mean(), cv_scores['test_f1_macro'].std() * 2))\n",
    "        \n",
    "        visual(X_train, y, classifier.classes_)\n",
    "    \n",
    "    elif algo == 'dummy':\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(3, 3), norm='l1', use_idf=True, max_features=1000, lowercase=True, stop_words=None, smooth_idf=True)\n",
    "        vectorizer.fit(x)\n",
    "        X_train = vectorizer.transform(x)\n",
    "        strategy='stratified'\n",
    "        print('\\n====DummyBaseline (%s)====' % strategy)\n",
    "        clf = DummyClassifier(strategy=strategy,random_state=42) # 'stratified','uniform', 'most_frequent'\n",
    "        \n",
    "        ## this function is simpler than cross_validate, it returns a list of scores on just one specified metric, rather than a dict and tons of other info in that dict\n",
    "        scores_f = cross_val_score(clf, X_train, y, cv=skf, scoring='f1_macro')  # cv = loo f1_macro\n",
    "        scores_acc = cross_val_score(clf, X_train, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "        print(\"F1 over 10folds: \", scores_f.mean())\n",
    "        print(\"Accuracy over 10folds: \", scores_acc.mean())\n",
    "\n",
    "        preds = cross_val_predict(clf, X_train, y, cv=skf)\n",
    "        print('Cross-validated estimates for data points')\n",
    "        print(classification_report(y, preds))\n",
    "\n",
    "        print('===ConfusionMatrix===')\n",
    "        cnf_matrix = confusion_matrix(y, preds)\n",
    "        print(cnf_matrix)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "#     return best_parameters, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'SVM']\n",
      "parameters:\n",
      "{'tfidf__max_features': (500, 1000, 5000), 'tfidf__use_idf': (True, False), 'SVM__gamma': [0.01, 0.1, 1, 10], 'SVM__C': [1, 10, 100], 'tfidf__norm': ('l1', 'l2')}\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 720 out of 720 | elapsed:  5.0min finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 303.223s\n",
      "\n",
      "Best score: 0.654\n",
      "Best parameters set:\n",
      "\tSVM__C: 100\n",
      "\tSVM__gamma: 1\n",
      "\ttfidf__max_features: 1000\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "accuracy= 0.9870848708487084\n",
      "macro f-score 0.9864760336352523\n",
      "Confusion matrix\n",
      " [[210   3]\n",
      " [  4 325]]\n",
      "=====\n",
      "Unpack the pipeline and look at some distinctive features and produce cross-validated metrics for the classifier on the weighted vectors\n",
      "features with lowest tfidf\n",
      "['бедствий были задержаны' 'пожертвований исследования показывают'\n",
      " 'собственным интересам не' 'были задержаны контрактными'\n",
      " 'приоритет своим собственным' 'николь берри показывает'\n",
      " 'своим собственным интересам' 'задержаны контрактными обязательствами'\n",
      " 'отдают приоритет своим' 'роль добровольный труд' 'как федеральные фонды'\n",
      " 'время как федеральные' 'поездки конечно бывают'\n",
      " 'утверждения которые начинаются' 'из четырех африканских'\n",
      " 'из собственного опыта' 'четырех африканских стран'\n",
      " 'для потенциальных международных' 'собственного опыта волонтерства'\n",
      " 'на утверждения которые']\n",
      "features with highest tfidf\n",
      "['на данный момент' 'по поводу того' 'на этой неделе' 'том что они'\n",
      " 'на самом деле' 'во всем мире' 'но все же' 'исследования показали что'\n",
      " 'так же как' 'на сегодняшний день' 'имеет право на'\n",
      " 'несет ответственность за' 'для того чтобы' 'тем не менее' 'на то чтобы'\n",
      " 'по большей части' 'то же время' 'брюссель апреля 2014' 'так как они'\n",
      " 'по меньшей мере']\n",
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "=====\n",
      "Here goes cross-validation. Please wait a bit...\n",
      "Average Precision on 10-fold cross-validation: 0.653 (+/- 0.110)\n",
      "Average Recall on 10-fold cross-validation: 0.653 (+/- 0.103)\n",
      "Average F1 on 10-fold cross-validation: 0.652 (+/- 0.106)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76f4ce7cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridsearch_SVM(Xraw, Y, refit_score='f1_score', algo='SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====DummyBaseline (stratified)====\n",
      "F1 over 10folds:  0.45515205668347775\n",
      "Accuracy over 10folds:  0.4889566879749509\n",
      "Cross-validated estimates for data points\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.34      0.31      0.32       213\n",
      "        good       0.57      0.61      0.59       329\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       542\n",
      "   macro avg       0.45      0.46      0.46       542\n",
      "weighted avg       0.48      0.49      0.48       542\n",
      "\n",
      "===ConfusionMatrix===\n",
      "[[ 65 148]\n",
      " [129 200]]\n"
     ]
    }
   ],
   "source": [
    "gridsearch_SVM(Xraw, Y, refit_score='f1_score', algo='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, with the sparse vectors like itidf it is more difficult to overfit; .todense() method change the format but not the nature of the vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "this is what you call an overfit model: 5000 features for 543 instances!\n"
     ]
    }
   ],
   "source": [
    "print('this is what you call an overfit model: 5000 features for 543 instances!', file=sys.stderr)\n",
    "print('However, with the sparse vectors like itidf it is more difficult to overfit; .todense() method change the format but not the nature of the vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
